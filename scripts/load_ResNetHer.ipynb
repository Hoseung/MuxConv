{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/fhe/lib/python3.10/site-packages/lightning_utilities/core/imports.py:132: Unbuilt egg for bbsQt [unknown version] (/home/hoseung/Work/FHE/Kinect_BBS_demo)\n",
      "/home/hoseung/anaconda3/envs/fhe/lib/python3.10/site-packages/lightning_utilities/core/imports.py:132: Unbuilt egg for bbsQt [unknown version] (/home/hoseung/Work/FHE/Kinect_BBS_demo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ResNetHer import ResNetHer\n",
    "from muxcnn.models.lightning import LitModel\n",
    "from muxcnn.utils import load_params, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_chk = \"./smooth_sep_bn.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetHer([1,1,1])#, hermite=True)#, activation=None)\n",
    "\n",
    "model.to('cuda')\n",
    "train_on_gpu=True\n",
    "\n",
    "# Instantiate the model and Lightning module\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lit_model = LitModel.load_from_checkpoint(fn_chk, \n",
    "                                          model=model, \n",
    "                                          criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = lit_model.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['hermitepn.gamma', 'hermitepn.beta', 'hermitepn.running_mean', 'hermitepn.running_var', 'hermitepn.running_mean2', 'hermitepn.running_var2', 'conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.conv2.weight', 'layer1.0.herPN1.gamma', 'layer1.0.herPN1.beta', 'layer1.0.herPN1.running_mean', 'layer1.0.herPN1.running_var', 'layer1.0.herPN1.running_mean2', 'layer1.0.herPN1.running_var2', 'layer1.0.herPN2.gamma', 'layer1.0.herPN2.beta', 'layer1.0.herPN2.running_mean', 'layer1.0.herPN2.running_var', 'layer1.0.herPN2.running_mean2', 'layer1.0.herPN2.running_var2', 'layer2.0.conv1.weight', 'layer2.0.conv2.weight', 'layer2.0.shortcut.0.weight', 'layer2.0.herPN1.gamma', 'layer2.0.herPN1.beta', 'layer2.0.herPN1.running_mean', 'layer2.0.herPN1.running_var', 'layer2.0.herPN1.running_mean2', 'layer2.0.herPN1.running_var2', 'layer2.0.herPN2.gamma', 'layer2.0.herPN2.beta', 'layer2.0.herPN2.running_mean', 'layer2.0.herPN2.running_var', 'layer2.0.herPN2.running_mean2', 'layer2.0.herPN2.running_var2', 'layer3.0.conv1.weight', 'layer3.0.conv2.weight', 'layer3.0.shortcut.0.weight', 'layer3.0.herPN1.gamma', 'layer3.0.herPN1.beta', 'layer3.0.herPN1.running_mean', 'layer3.0.herPN1.running_var', 'layer3.0.herPN1.running_mean2', 'layer3.0.herPN1.running_var2', 'layer3.0.herPN2.gamma', 'layer3.0.herPN2.beta', 'layer3.0.herPN2.running_mean', 'layer3.0.herPN2.running_var', 'layer3.0.herPN2.running_mean2', 'layer3.0.herPN2.running_var2', 'linear.weight', 'linear.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from muxcnn.models.ResNet20 import ResNet, BasicBlock\n",
    "\n",
    "fn_chk2 = \"./ResNet8.pt\"\n",
    "device=\"cpu\"\n",
    "\n",
    "model = ResNet(BasicBlock,[1,1,1])\n",
    "model.eval() \n",
    "\n",
    "trained_param = torch.load(fn_chk2, map_location = torch.device(device))\n",
    "if 'state_dict' in trained_param.keys():\n",
    "    trained_param = trained_param['state_dict']\n",
    "    print(\"[INFO] extracting state_dict from the checkpoint\")\n",
    "\n",
    "trained_param = {key : value.cpu() for key,value in trained_param.items()}\n",
    "model.load_state_dict(trained_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.shortcut.0.weight', 'layer2.0.shortcut.1.running_mean', 'layer2.0.shortcut.1.running_var', 'layer2.0.shortcut.1.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.shortcut.0.weight', 'layer3.0.shortcut.1.running_mean', 'layer3.0.shortcut.1.running_var', 'layer3.0.shortcut.1.num_batches_tracked', 'linear.weight', 'linear.bias'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comapre MuxedHer and TorchHer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "model = ResNetHer([1,1,1])#, hermite=True)#, activation=None)\n",
    "model.eval()\n",
    "model.to('cpu')\n",
    "\n",
    "# Instantiate the model and Lightning module\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lit_model = LitModel.load_from_checkpoint(fn_chk, \n",
    "                                          model=model, \n",
    "                                          criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = load_img(\"./cute.jpg\", hi=32, wi=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PyTorch] It's a dog\n"
     ]
    }
   ],
   "source": [
    "torch_result = lit_model(img_tensor)\n",
    "torch_class = torch.argmax(torch_result)\n",
    "print(f\"[PyTorch] It's a {classes[torch_class]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muxcnn.resnet_muxconvHer import ResNet_MuxConvHer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "muxed_model = ResNet_MuxConvHer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MultParConv] (hi,wi,ci,ki,ti,pi) =(32,32, 3, 1, 3,  8)\n",
      "[MultParConv] (ho,wo,co,ko,to,po) =(32,32,16, 1,16,  2)\n",
      "[MultParConv] q = 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "parMuxBN_separate() missing 2 required positional arguments: 'outs' and 'nslots'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmuxed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/FHE/MuxConv/muxcnn/resnet_muxconvHer.py:130\u001b[0m, in \u001b[0;36mResNet_MuxConvHer.__call__\u001b[0;34m(self, img_tensor)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_tensor):\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Work/FHE/MuxConv/muxcnn/resnet_muxconvHer.py:57\u001b[0m, in \u001b[0;36mResNet_MuxConvHer.forward\u001b[0;34m(self, img_tensor)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_tensor):\n\u001b[1;32m     56\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtorch_model\n\u001b[0;32m---> 57\u001b[0m     ctxt, outs0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_early_Her\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Basic blocks\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     ctxt, outs1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_bb_Her(model\u001b[38;5;241m.\u001b[39mlayer1[\u001b[38;5;241m0\u001b[39m], ctxt, outs0)\n",
      "File \u001b[0;32m~/Work/FHE/MuxConv/muxcnn/resnet_muxconvHer.py:79\u001b[0m, in \u001b[0;36mResNet_MuxConvHer.forward_early_Her\u001b[0;34m(self, img_tensor)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# ctxt, un1 = forward_convbn_par(model.conv1, \u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#                                model.bn1, ct_a, ins0)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m ctxt, un1 \u001b[38;5;241m=\u001b[39m forward_conv_par(model\u001b[38;5;241m.\u001b[39mconv1, ct_a, ins0)\n\u001b[0;32m---> 79\u001b[0m ctxt \u001b[38;5;241m=\u001b[39m \u001b[43mhermitePN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhermitepn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# ctxt = self.activation(ctxt)\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# ctxt = self.herPN1(ctxt)\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctxt, outs0\n",
      "File \u001b[0;32m~/Work/FHE/MuxConv/muxcnn/hecnn_par.py:140\u001b[0m, in \u001b[0;36mhermitePN\u001b[0;34m(ctxt, bn_layer)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Normalize and scale\u001b[39;00m\n\u001b[1;32m    139\u001b[0m h0_bn \u001b[38;5;241m=\u001b[39m h0 \u001b[38;5;241m*\u001b[39m f0\n\u001b[0;32m--> 140\u001b[0m h1_bn \u001b[38;5;241m=\u001b[39m \u001b[43mparMuxBN_separate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf1\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbn_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m h2_bn \u001b[38;5;241m=\u001b[39m parMuxBN_separate(f2\u001b[38;5;241m*\u001b[39mh2, bn_layer, term\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    143\u001b[0m result \u001b[38;5;241m=\u001b[39m h0_bn \u001b[38;5;241m+\u001b[39m h1_bn \u001b[38;5;241m+\u001b[39m h2_bn\n",
      "\u001b[0;31mTypeError\u001b[0m: parMuxBN_separate() missing 2 required positional arguments: 'outs' and 'nslots'"
     ]
    }
   ],
   "source": [
    "result = muxed_model(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
